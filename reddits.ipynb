{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMakfN9bn0CB"
      },
      "source": [
        "<h1>UST Reddit Projecy</h1></r>\n",
        "<h2>Pipeline</h2>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gives accessibility to my goodle drive to fetch the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmIuSrbLeJLQ",
        "outputId": "605d7ac7-293f-4e30-86aa-a059c3745af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7xATcS5n0CD"
      },
      "source": [
        "<h2>Generate dataset</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1dZSTNTn0CD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuCLqUN4n0CE"
      },
      "source": [
        "<h3>Read the raw data WITHOUT CLEANING</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GbQ4ljtn0CE",
        "outputId": "70950837-9915-41c4-e356-0ef314e3d881"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>author</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>clean_selftext</th>\n",
              "      <th>num_title_emojis</th>\n",
              "      <th>num_text_emojis</th>\n",
              "      <th>title_length</th>\n",
              "      <th>text_length</th>\n",
              "      <th>score</th>\n",
              "      <th>num_replied_comments</th>\n",
              "      <th>num_replies_by_new</th>\n",
              "      <th>list_new_repliers</th>\n",
              "      <th>num_replies_by_old</th>\n",
              "      <th>list_old_repliers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mhj2yd</td>\n",
              "      <td>USWD_Bank</td>\n",
              "      <td>1.617235e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NFT Collectable USWD United States Web Dollar</td>\n",
              "      <td>removed</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mhj3di</td>\n",
              "      <td>[deleted]</td>\n",
              "      <td>1.617235e+09</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Not use to Green Only use to Red</td>\n",
              "      <td>deleted</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>,VisualMod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mhj3ew</td>\n",
              "      <td>KingMacias1</td>\n",
              "      <td>1.617235e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>We made it to Vice News you dirty apes Any pub...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mhj3oa</td>\n",
              "      <td>jt989898</td>\n",
              "      <td>1.617235e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Polygon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mhj3vq</td>\n",
              "      <td>KenAdamsonPrime</td>\n",
              "      <td>1.617235e+09</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Ubiquiti UI gets PWND by hackers stock goes up</td>\n",
              "      <td>removed</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>,AutoModerator,VisualMod</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id           author   created_utc  num_comments  \\\n",
              "0  mhj2yd        USWD_Bank  1.617235e+09           0.0   \n",
              "1  mhj3di        [deleted]  1.617235e+09           1.0   \n",
              "2  mhj3ew      KingMacias1  1.617235e+09           0.0   \n",
              "3  mhj3oa         jt989898  1.617235e+09           0.0   \n",
              "4  mhj3vq  KenAdamsonPrime  1.617235e+09           2.0   \n",
              "\n",
              "                                         clean_title clean_selftext  \\\n",
              "0      NFT Collectable USWD United States Web Dollar        removed   \n",
              "1                   Not use to Green Only use to Red        deleted   \n",
              "2  We made it to Vice News you dirty apes Any pub...            NaN   \n",
              "3                                            Polygon            NaN   \n",
              "4     Ubiquiti UI gets PWND by hackers stock goes up        removed   \n",
              "\n",
              "   num_title_emojis  num_text_emojis  title_length  text_length  score  \\\n",
              "0               0.0              NaN           7.0          NaN    1.0   \n",
              "1               0.0              NaN           8.0          NaN    1.0   \n",
              "2               1.0              0.0          14.0          0.0    1.0   \n",
              "3               0.0              0.0           1.0          0.0    1.0   \n",
              "4               0.0              NaN           9.0          NaN    1.0   \n",
              "\n",
              "   num_replied_comments  num_replies_by_new list_new_repliers  \\\n",
              "0                   0.0                 0.0               NaN   \n",
              "1                   1.0                 0.0               NaN   \n",
              "2                   0.0                 0.0               NaN   \n",
              "3                   0.0                 0.0               NaN   \n",
              "4                   1.0                 0.0               NaN   \n",
              "\n",
              "   num_replies_by_old         list_old_repliers  \n",
              "0                 0.0                       NaN  \n",
              "1                 1.0                ,VisualMod  \n",
              "2                 0.0                       NaN  \n",
              "3                 0.0                       NaN  \n",
              "4                 2.0  ,AutoModerator,VisualMod  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp = '/Users/victor/Desktop/CS/UST_summer/all_posts_clean_1.csv' # the directory of the raw data file, pipeliend from reddits\n",
        "\n",
        "s_columns = ['id', 'author', 'created_utc', 'num_comments', 'clean_title', 'clean_selftext', 'num_title_emojis', 'num_text_emojis', 'title_length', 'text_length', 'score', 'num_replied_comments', 'num_replies_by_new', 'list_new_repliers', 'num_replies_by_old', 'list_old_repliers']\n",
        "\n",
        "df = pd.read_csv(fp, low_memory=False, encoding='utf-8')[s_columns]\n",
        "\n",
        "df.head() # test if it is read correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNXN3S32n0CE"
      },
      "outputs": [],
      "source": [
        "# df = df[df.created_utc < 1590000000.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDPlszy6n0CF",
        "outputId": "072d52d1-4985-4765-b016-1b8238463724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.7724909782409668 seconds ---\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "df.groupby('author').cumcount()\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "df[\"num_post\"] = df.groupby('author').cumcount().to_numpy()\n",
        "codes, uniques = pd.factorize(df[\"author\"])\n",
        "df[\"author_codes\"] = codes\n",
        "\n",
        "# df.to_csv('wsb_with_authorcode_num_post.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGy-bVvFn0CF"
      },
      "source": [
        "<h2>for statistical tests ONLY</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlVRJONQn0CF"
      },
      "outputs": [],
      "source": [
        "indices = df.index[(df.created_utc >= 1609459200.0) & (df.created_utc <= 1612137599.0)].tolist()\n",
        "\n",
        "# zeros = np.zeros(df.shape[0])\n",
        "# for i in indices : zeros[i] = 1\n",
        "\n",
        "# df['is_2021Jan'] = zeros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzIWsZ-On0CG",
        "outputId": "ead05f8f-9fcd-444b-e13e-1bbfd9f1862d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1059964"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "number_of_replies = list()\n",
        "\n",
        "index = df.index[(df['clean_selftext'] == 'deleted') | (df['clean_selftext'] == 'removed')].tolist()\n",
        "for i in index:\n",
        "    number_of_replies.append(df['num_comments'].iloc[i])\n",
        "    \n",
        "# len(number_of_replies)\n",
        "\n",
        "nonzero_replies = np.count_nonzero(np.array(number_of_replies))\n",
        "nonzero_replies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF_KjIx9n0CG",
        "outputId": "67d9da3b-dd76-4bb6-cfe7-d0976caada9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1553189, 19)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTzczjq0n0CG"
      },
      "outputs": [],
      "source": [
        "# count the number of deleted and removed comments in each month from 2020-01-01 to 2021-05-01\n",
        "date = datetime(2020,1,1,0)\n",
        "time = []\n",
        "\n",
        "for i in range(17):\n",
        "    count_time = date + relativedelta(months=i)\n",
        "    count_time = count_time.timestamp()\n",
        "    time.append(count_time)\n",
        "\n",
        "time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXA_8IDjn0CH"
      },
      "outputs": [],
      "source": [
        "def deleted_comments(left_bound, right_bound, dataframe):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        left_bound (_type_): _description_\n",
        "        right_bound (_type_): _description_\n",
        "        dataframe (_type_): _description_\n",
        "    \"\"\"\n",
        "    indices = dataframe.index[(dataframe.created_utc >= left_bound) & (dataframe.created_utc <= right_bound)].tolist() # workout the total number of comments\n",
        "    \n",
        "    # print(indices)\n",
        "    if len(indices) == 0:\n",
        "        return 0\n",
        "    \n",
        "    unwanted_comments = 0\n",
        "    for i in indices:\n",
        "        if (dataframe['clean_selftext'].iloc[i] == 'deleted') | (dataframe['clean_selftext'].iloc[i] == 'removed'):\n",
        "            unwanted_comments += 1\n",
        "    \n",
        "    return (unwanted_comments/len(indices))*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym8wftLhn0CH"
      },
      "outputs": [],
      "source": [
        "# workout the percentage of deleted commenets within the time range\n",
        "unwanted_percent = []\n",
        "\n",
        "for i in range (len(time)-1):\n",
        "    left = time[i]\n",
        "    right = time[i+1]\n",
        "    \n",
        "    \n",
        "    unwanted_percent.append(deleted_comments(left,right,df))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WisDbEOGn0CH"
      },
      "outputs": [],
      "source": [
        "def replied_percent(left_bound, right_bound, dataframe):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        left_bound (_type_): _description_\n",
        "        right_bound (_type_): _description_\n",
        "        dataframe (_type_): _description_\n",
        "    \"\"\"\n",
        "    indices = dataframe.index[(dataframe.created_utc >= left_bound) & (dataframe.created_utc <= right_bound)].tolist()\n",
        "    \n",
        "    negative_index = []\n",
        "    negative_positive = 0\n",
        "    \n",
        "    for i in indices:\n",
        "        if (dataframe['clean_selftext'].iloc[i] == 'deleted') | (dataframe['clean_selftext'].iloc[i] == 'removed'):\n",
        "            negative_index.append(i)\n",
        "    \n",
        "    for i in negative_index:\n",
        "        if dataframe.num_comments.iloc[i] > 0:\n",
        "            negative_positive += 1\n",
        "    \n",
        "    negative_positive_rate = negative_positive / len(negative_index)\n",
        "    \n",
        "    positive_index = list(set(indices) - set(negative_index))\n",
        "    positive_positive = 0\n",
        "    \n",
        "    for i in positive_index:\n",
        "        if dataframe.num_comments.iloc[i] > 0:\n",
        "            positive_positive += 1\n",
        "    \n",
        "    positive_positive_rate = positive_positive / len(positive_index)\n",
        "    \n",
        "    return (positive_positive_rate, negative_positive_rate)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# workout the percentage of undeleted commenets got replied and deleted comments got replied within the time range\n",
        "reply_percent = []\n",
        "\n",
        "for i in range (len(time)-1):\n",
        "    left = time[i]\n",
        "    right = time[i+1]\n",
        "    \n",
        "    \n",
        "    reply_percent.append(replied_percent(left,right,df))"
      ],
      "metadata": {
        "id": "_y_NdrcGvDhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reply_percent)"
      ],
      "metadata": {
        "id": "6xCGG4npvGFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AinB (A, B):\n",
        "    check =  any(item in A for item in B)\n",
        "    return check\n",
        "\n",
        "def del_bot(name):\n",
        "    tokens = re.split('[^a-zA-Z]', name)\n",
        "    \n",
        "    not_list = ['not', 'Not', 'NOt', 'NOT', 'nOt', 'nOT', 'noT', 'NoT']\n",
        "    \n",
        "    bot_list = ['bot', 'Bot', 'BOt', 'BOT', 'bOt', 'bOT', 'boT', 'BoT']\n",
        "    \n",
        "    if AinB(not_list, tokens) and AinB(bot_list, tokens):\n",
        "        return False\n",
        "\n",
        "    elif AinB(bot_list, tokens):\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "metadata": {
        "id": "I386PXr4T72C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a copy of the dataframe\n",
        "botless_df = df.copy()\n",
        "\n",
        "drop_indices = []\n",
        "\n",
        "for i in range (len(botless_df['author'])):\n",
        "    if del_bot(botless_df.author.iloc[i]):\n",
        "        drop_indices.append(i)\n",
        "drop_indices"
      ],
      "metadata": {
        "id": "SPmlIfjiT8jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "botless_df = botless_df.loc[~botless_df.index.isin(drop_indices)]"
      ],
      "metadata": {
        "id": "Hx__P5qea90i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# workout the percentage of deleted commenets within the time range\n",
        "botless_unwanted_percent = []\n",
        "\n",
        "for i in range (len(time)-1):\n",
        "    left = time[i]\n",
        "    right = time[i+1]\n",
        "    \n",
        "    \n",
        "    botless_unwanted_percent.append(deleted_comments(left,right,botless_df))"
      ],
      "metadata": {
        "id": "wnWP1Imxe62_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "botless_unwanted_percent"
      ],
      "metadata": {
        "id": "le3XNzd9e8k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# workout the percentage of undeleted commenets got replied and deleted comments got replied within the time range\n",
        "botless_reply_percent = []\n",
        "\n",
        "for i in range (len(time)-1):\n",
        "    left = time[i]\n",
        "    right = time[i+1]\n",
        "    \n",
        "    \n",
        "    botless_reply_percent.append(replied_percent(left,right,botless_df))"
      ],
      "metadata": {
        "id": "U3h47BlMe-hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "botless_reply_percent"
      ],
      "metadata": {
        "id": "p9talnUwfAiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Change to use the new datasets</h2>\n",
        "Utility function that helps to split the monthly dataset into daily ones"
      ],
      "metadata": {
        "id": "emGcmmGcdDNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function that works out the timestamps of each day in a month\n",
        "def workout_time(year, month):\n",
        "  max_day = 31\n",
        "  month_list = [4, 6, 9, 11]\n",
        "\n",
        "  if year == 2020 and month == 2:\n",
        "    max_day = 29\n",
        "  elif month == 2:\n",
        "    max_day = 28\n",
        "  elif month in month_list:\n",
        "    max_day = 30\n",
        "  \n",
        "  start_date = datetime(year, month, 1, 0) # always start at the first day on each month\n",
        "\n",
        "  day_list = []\n",
        "\n",
        "  for i in range(max_day):\n",
        "    count_time = start_date + relativedelta(days=i)\n",
        "    count_time = count_time.timestamp()\n",
        "    day_list.append(count_time)\n",
        "  \n",
        "  return day_list"
      ],
      "metadata": {
        "id": "5nF9sPcge_Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a funtion that creates sub_dataframes from the parent dataframe based on number of days\n",
        "def create_subframe(day_list, parent_dataframe):\n",
        "  df_list = []\n",
        "\n",
        "  for i in range(len(day_list)-1):\n",
        "    left = day_list[i]\n",
        "    right = day_list[i+1]\n",
        "\n",
        "    day_df = parent_dataframe[(parent_dataframe.created_utc >= left) & (parent_dataframe.created_utc < right)]\n",
        "    \n",
        "    df_list.append(day_df)\n",
        "  \n",
        "  return df_list\n"
      ],
      "metadata": {
        "id": "RAAPYc-gffoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "utility function to workout the centrality of the given dataframe"
      ],
      "metadata": {
        "id": "3KuwmlP_jzrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>exmaine the monthly dataset</h3>"
      ],
      "metadata": {
        "id": "PFYqLtfIj6QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we want to examine the 01-20 comments file\n",
        "df_01_20 = pd.read_csv('/content/drive/MyDrive/UST_summer/01-20_comments.csv')"
      ],
      "metadata": {
        "id": "zpI3tqfefhIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Clean the dataset first</h4>"
      ],
      "metadata": {
        "id": "DSa4tZGRCHxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_indices = []\n",
        "\n",
        "def remove_parent_bot(authors_dataframe, dataframe):\n",
        "    j = authors_dataframe.columns.get_loc(\"parent_id\")\n",
        "    for i in range (len(authors_dataframe['parent_id'])):\n",
        "        split_id = str(authors_dataframe.iloc[i, j]).split(\"_\")[1]\n",
        "        authorname = dataframe.loc[dataframe['id'] == split_id, 'author'].tolist()\n",
        "        if authorname == []:\n",
        "            continue\n",
        "        else:\n",
        "            if del_bot(authorname[0]):\n",
        "                print('yes')\n",
        "                drop_indices.append(str(authors_dataframe.iloc[i, j]))\n",
        "    drop_indices"
      ],
      "metadata": {
        "id": "fIDuQnafCki-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_parent_children_df(dataframe):\n",
        "    tqdm.pandas()\n",
        "    level_1_comments = dataframe[dataframe['parent_id'] == dataframe['link_id']]\n",
        "\n",
        "    sub_comments = dataframe[~dataframe.index.isin(level_1_comments.index)] #setting the sub comments being those with index that are not in level_1_comments\n",
        "\n",
        "    posts_authors  = sub_comments.groupby('parent_id')['author', 'created_utc'].apply(list).reset_index(name='author')\n",
        "    posts_authors['sub_comments'] = posts_authors['author'].progress_apply(lambda x:len(x))\n",
        "    post_authors['created_utc'] \n",
        "    posts_authors.sort_values('sub_comments', inplace=True, ascending=False)\n",
        "\n",
        "    return posts_authors"
      ],
      "metadata": {
        "id": "817RWf70PvLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_name_id_dict(dataframe):\n",
        "    name_id = {}\n",
        "    for i in range(dataframe.shape[0]):\n",
        "        key = dataframe.id.iloc[i]\n",
        "        value = dataframe.author.iloc[i]\n",
        "\n",
        "        key_value_pair = {key:value}\n",
        "\n",
        "        name_id.update(key_value_pair)\n",
        "    return name_id"
      ],
      "metadata": {
        "id": "60zU2imePvt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_by_parent(parent_children_dataframe, name_id_dicitonary):\n",
        "    drop_indices = []\n",
        "    parent_ids = parent_children_dataframe.parent_id\n",
        "    indices = parent_children_dataframe.index\n",
        "    for i in range(len(parent_ids)):\n",
        "        uid = parent_ids[i].split('_')[-1]\n",
        "        # use the dictionary to find the corresponding author name\n",
        "        try:\n",
        "            author_name = name_id_dicitonary[uid]\n",
        "        except:\n",
        "            continue\n",
        "        if del_bot(author_name):\n",
        "            drop_indices.append(indices[i])\n",
        "    \n",
        "    return drop_indices"
      ],
      "metadata": {
        "id": "29TuVkV5P1cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_author(parent_children_dataframe):\n",
        "    for i in range(parent_children_dataframe.shape[0]):\n",
        "        bot = False\n",
        "        df_index = parent_children_dataframe.index\n",
        "        author_list = parent_children_dataframe.author.iloc[i]\n",
        "        # print(author_list)\n",
        "        for author in author_list:\n",
        "            if del_bot(author):\n",
        "                author_list.remove(author)\n",
        "                bot = True\n",
        "                # print(1)\n",
        "        if bot:\n",
        "            # print(1)\n",
        "            parent_children_dataframe.loc[df_index[i]].at['author'] = author_list\n",
        "            parent_children_dataframe.loc[df_index[i]].at['sub_comments'] = len(author_list)\n",
        "    \n",
        "    return parent_children_dataframe"
      ],
      "metadata": {
        "id": "BDWUycouaYkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------"
      ],
      "metadata": {
        "id": "KL2Mnsw-CQvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year, month = 2020, 1\n",
        "day_list_01_20 = workout_time(year, month)"
      ],
      "metadata": {
        "id": "HV2sD2WFkCbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_list_01_20 = create_subframe(day_list_01_20, df_01_20)"
      ],
      "metadata": {
        "id": "8V_2vzRTkLpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_list_01_20"
      ],
      "metadata": {
        "id": "07jFtLn5kTGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create adjacency matrix:\n"
      ],
      "metadata": {
        "id": "s2oE2WP37oSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_authors(name_id_dict, child_parent_df):\n",
        "    author_list = []\n",
        "    j = child_parent_df.columns.get_loc(\"parent_id\")\n",
        "    for i in range(len(child_parent_df)):\n",
        "        ids = str(child_parent_df.iloc[i, j]).split(\"_\")[1]\n",
        "        try:\n",
        "            a_name = name_id_dict[ids]\n",
        "            if a_name not in author_list:\n",
        "                author_list.append(name_id_dict[ids])\n",
        "        except:\n",
        "            print('the parent post is created in a prior date')\n",
        "            \n",
        "        a_list = child_parent_df.author.iloc[i]\n",
        "        for authors in a_list:\n",
        "            if authors not in author_list:\n",
        "                    author_list.append(authors)\n",
        "    return author_list"
      ],
      "metadata": {
        "id": "ULtoXKqJ7LUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_authors(name_id_dict, dataframe):\n",
        "    author_list = set()\n",
        "    for i in range(dataframe.shape[0]):\n",
        "        print(i)\n",
        "        uid = dataframe.parent_id.iloc[i].split('_')[-1]\n",
        "\n",
        "        try:\n",
        "            author_list.add(name_id_dict[uid])\n",
        "        except:\n",
        "            print('the parent post is created in a prior date')\n",
        "\n",
        "        author_list.update(tuple(dataframe.author.iloc[i]))\n",
        "        \n",
        "    return author_list"
      ],
      "metadata": {
        "id": "nPVEvSOl_XBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adjacency_matrix(adj_matrix, p_c_df, name_dict):\n",
        "    for i in adj_matrix.index:\n",
        "        for k in range(p_c_df.shape[0]):\n",
        "            author_list = p_c_df.author.iloc[k]\n",
        "            if i in author_list:\n",
        "                parent_name = p_c_df.parent_id.iloc[k].split(\"_\")[1]\n",
        "                try:\n",
        "                    p_name = name_dict[parent_name]\n",
        "                    print(p_name)\n",
        "                    adj_matrix.loc[i, p_name] += 1\n",
        "                    print(adj_matrix.loc[i, p_name])\n",
        "                except:\n",
        "                    continue\n",
        "    return adj_matrix"
      ],
      "metadata": {
        "id": "rFsEogYY7MOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adj_matrix(author_list, dataframe, name_id_dict):\n",
        "    adj_matrix = pd.DataFrame(0, index = author_list, columns = author_list)\n",
        "    for i in range(dataframe.shape[0]):\n",
        "        uid = dataframe.parent_id.iloc[i].split('_')[-1]\n",
        "        \n",
        "        try:\n",
        "            parent_name = name_id_dict[uid]\n",
        "        except:\n",
        "            continue\n",
        "        author_list = dataframe.author.iloc[i]\n",
        "\n",
        "        for author in author_list:\n",
        "            adj_matrix.loc[author, parent_name] += 1\n",
        "    \n",
        "    return adj_matrix"
      ],
      "metadata": {
        "id": "Ifvh-rLxIkkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_matrix = pd.DataFrame(0, index = author_list, columns = author_list)"
      ],
      "metadata": {
        "id": "bNl8LhJG7a0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_matrix = generate_adjacency_matrix(a_matrix, posts_authors, name_id)"
      ],
      "metadata": {
        "id": "6xF9N0rd7TJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "soFywNiO7Ve-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Formal Workflow**"
      ],
      "metadata": {
        "id": "qXOjnBXfN-IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import re\n",
        "import networkx as nx\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "srIvgdX4OE36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fp1 = \"/Users/jerrylin/Downloads/01-20_comments.csv\"\n",
        "df_01 = pd.read_csv(fp1, low_memory = False, encoding = 'utf-8')  #get the Jan-2020 spreadsheet\n",
        "df_01 = df_01[df_01.author != '[deleted]'] #remove authors that are deleted\n"
      ],
      "metadata": {
        "id": "cX9byS0fOXSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function that works out the timestamps of each day in a month\n",
        "def workout_time(year, month):\n",
        "  max_day = 31\n",
        "  month_list = [4, 6, 9, 11]\n",
        "\n",
        "  if year == 2020 and month == 2:\n",
        "    max_day = 29\n",
        "  elif month == 2:\n",
        "    max_day = 28\n",
        "  elif month in month_list:\n",
        "    max_day = 30\n",
        "  \n",
        "  start_date = datetime(year, month, 1, 0) # always start at the first day on each month\n",
        "\n",
        "  day_list = []\n",
        "\n",
        "  for i in range(max_day):\n",
        "    count_time = start_date + relativedelta(days=i)\n",
        "    count_time = count_time.timestamp()\n",
        "    day_list.append(count_time)\n",
        "  \n",
        "  return day_list\n",
        "\n",
        "# a funtion that creates sub_dataframes from the parent dataframe based on number of days\n",
        "def create_subframe(day_list, parent_dataframe):\n",
        "  df_list = []\n",
        "\n",
        "  for i in range(len(day_list)-1):\n",
        "    left = day_list[i]\n",
        "    right = day_list[i+1]\n",
        "\n",
        "    day_df = parent_dataframe[(parent_dataframe.created_utc >= left) & (parent_dataframe.created_utc < right)]\n",
        "    \n",
        "    df_list.append(day_df)\n",
        "  \n",
        "  return df_list\n",
        "\n",
        "# a funtion that creates sub_dataframes from the parent dataframe based on number of days\n",
        "def create_subframe(day_list, parent_dataframe):\n",
        "  df_list = []\n",
        "\n",
        "  for i in range(len(day_list)-1):\n",
        "    left = day_list[i]\n",
        "    right = day_list[i+1]\n",
        "\n",
        "    day_df = parent_dataframe[(parent_dataframe.created_utc >= left) & (parent_dataframe.created_utc < right)]\n",
        "    \n",
        "    df_list.append(day_df)\n",
        "  \n",
        "  return df_list"
      ],
      "metadata": {
        "id": "Jk3VVx6oOxGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year, month = 2020, 1\n",
        "day_list_01_20 = workout_time(year, month)\n",
        "df_list_01_20 = create_subframe(day_list_01_20, df_01)   #creates day-by-day sub-dataframes"
      ],
      "metadata": {
        "id": "HGgUqtBOOyDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bot removal\n",
        "def AinB (A, B):\n",
        "    check =  any(item in A for item in B)\n",
        "    return check\n",
        "\n",
        "def del_bot(name):\n",
        "    tokens = re.split('[^a-zA-Z]', name)\n",
        "    \n",
        "    not_list = ['not', 'Not', 'NOt', 'NOT', 'nOt', 'nOT', 'noT', 'NoT']\n",
        "    \n",
        "    bot_list = ['bot', 'Bot', 'BOt', 'BOT', 'bOt', 'bOT', 'boT', 'BoT']\n",
        "    \n",
        "    if AinB(not_list, tokens) and AinB(bot_list, tokens):\n",
        "        return False\n",
        "\n",
        "    elif AinB(bot_list, tokens):\n",
        "        return True\n",
        "    \n",
        "    return False"
      ],
      "metadata": {
        "id": "wXn33CQWO6pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_indices = []\n",
        "\n",
        "\n",
        "    drop_indices\n",
        "    \n",
        "def create_parent_children_df(dataframe):     #create the output dataframe\n",
        "    tqdm.pandas()\n",
        "    level_1_comments = dataframe[dataframe['parent_id'] == dataframe['link_id']]\n",
        "\n",
        "    sub_comments = dataframe[~dataframe.index.isin(level_1_comments.index)] #setting the sub comments being those with index that are not in level_1_comments\n",
        "\n",
        "    posts_authors  = sub_comments.groupby('parent_id')['author'].apply(list).reset_index(name='author')\n",
        "    posts_authors['sub_comments'] = posts_authors['author'].progress_apply(lambda x:len(x))\n",
        "    posts_authors.sort_values('sub_comments', inplace=True, ascending=False)\n",
        "\n",
        "    return posts_authors\n",
        "\n",
        "def create_name_id_dict(dataframe):    #create id:author dataframe\n",
        "    name_id = {}\n",
        "    for i in range(dataframe.shape[0]):\n",
        "        key = dataframe.id.iloc[i]\n",
        "        value = dataframe.author.iloc[i]\n",
        "\n",
        "        key_value_pair = {key:value}\n",
        "\n",
        "        name_id.update(key_value_pair)\n",
        "    return name_id\n",
        "\n",
        "def clean_by_parent(parent_children_dataframe, name_id_dicitonary):   #clean bots from parent_id\n",
        "    drop_indices = []\n",
        "    parent_ids = parent_children_dataframe.parent_id\n",
        "    indices = parent_children_dataframe.index\n",
        "    for i in range(len(parent_ids)):\n",
        "        id = parent_ids[i].split('_')[-1]\n",
        "        # use the dictionary to find the corresponding author name\n",
        "        try:\n",
        "            author_name = name_id_dicitonary[id]\n",
        "        except:\n",
        "            continue\n",
        "        if del_bot(author_name):\n",
        "            drop_indices.append(indices[i])\n",
        "    \n",
        "    return drop_indices\n",
        "\n",
        "def clean_author(parent_children_dataframe):    #clean bots from authors\n",
        "    for i in range(parent_children_dataframe.shape[0]):\n",
        "        bot = False\n",
        "        df_index = parent_children_dataframe.index\n",
        "        author_list = parent_children_dataframe.author.iloc[i]\n",
        "        # print(author_list)\n",
        "        for author in author_list:\n",
        "            if del_bot(author):\n",
        "                author_list.remove(author)\n",
        "                bot = True\n",
        "                # print(1)\n",
        "        if bot:\n",
        "            # print(1)\n",
        "            parent_children_dataframe.loc[df_index[i]].at['author'] = author_list\n",
        "            parent_children_dataframe.loc[df_index[i]].at['sub_comments'] = len(author_list)\n",
        "    \n",
        "    return parent_children_dataframe"
      ],
      "metadata": {
        "id": "q6Ei8C09PBax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_df = df_list_01_20[1]\n",
        "posts_authors = create_parent_children_df(day_df)\n",
        "name_id = create_name_id_dict(day_df)\n",
        "drop_indices = clean_by_parent(posts_authors, name_id)\n",
        "drop_indices\n",
        "posts_authors = posts_authors.drop(drop_indices)\n",
        "posts_authors = clean_author(posts_authors)\n",
        "posts_authors"
      ],
      "metadata": {
        "id": "UoMYeMZkPqy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_authors(name_id_dict, dataframe):   #get all author names\n",
        "    author_list = set()\n",
        "    for i in range(dataframe.shape[0]):\n",
        "        uid = dataframe.parent_id.iloc[i].split('_')[-1]\n",
        "\n",
        "        try:\n",
        "            author_list.add(name_id_dict[uid])\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        author_list.update(tuple(dataframe.author.iloc[i]))\n",
        "        \n",
        "    return author_list\n",
        "\n",
        "def generate_adj_matrix(author_list, dataframe, name_id_dict):   #generate the adjacency matrix\n",
        "    adj_matrix = pd.DataFrame(0, index = author_list, columns = author_list)\n",
        "    for i in range(dataframe.shape[0]):\n",
        "        uid = dataframe.parent_id.iloc[i].split('_')[-1]\n",
        "        \n",
        "        try:\n",
        "            parent_name = name_id_dict[uid]\n",
        "        except:\n",
        "            continue\n",
        "        author_list = dataframe.author.iloc[i]\n",
        "\n",
        "        for author in author_list:\n",
        "            adj_matrix.loc[author, parent_name] += 1\n",
        "    \n",
        "    return adj_matrix"
      ],
      "metadata": {
        "id": "2Z3e-LI7P7nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "author_list = get_all_authors(name_id, posts_authors)\n",
        "generate_adj_matrix(author_list, posts_authors, name_id)\n",
        "adj_matrix.to_csv('file name')"
      ],
      "metadata": {
        "id": "mQA2DeoYQGsY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "864791b727c67594ba35b846e2fef3ab0cf2138c660c288cb4b982d81a4cb57f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "reddits.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}