{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1>HKUST-Ukarine</h1></br>\n",
        "Libraries and Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5g7W1vacxQuV"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from cleantext import clean\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Clean the script</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the unwanted entities in the html by regular expression\n",
        "# CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
        "\n",
        "def cleanhtml(raw_html, cleaner):\n",
        "    \"\"\"\n",
        "    a function to remove the unwanted entities (including emojis) in a html script\n",
        "    Args:\n",
        "        raw_html (string): the string of the html script\n",
        "        cleaner (__type__): the unwated entities\n",
        "    Returns:\n",
        "        clean_text (string): return the cleaned text\n",
        "    \"\"\"\n",
        "    no_emoji_text = emoji.replace_emoji(raw_html, replace='') # clean the emojis\n",
        "    \n",
        "    CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6}){;}*')\n",
        "    clean_text = re.sub(cleaner, '', raw_html) # clean the html entities\n",
        "    clean_text = re.sub(r'https://\\S+', '', clean_text) # remove links\n",
        "    \n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def file_manager(file_path):\n",
        "    \n",
        "    # create a data frame\n",
        "    df = pd.read_csv(file_path)\n",
        "    obs = len(df)\n",
        "    \n",
        "    # print(obs)\n",
        "    new_col = np.zeros((obs, ))\n",
        "    df[\"clean_title\"] = new_col\n",
        "    df[\"clean_text\"] = new_col\n",
        "    j = df.columns.get_loc(\"title\")\n",
        "    k = df.columns.get_loc(\"selftext\")\n",
        "    j_iloc = df.columns.get_loc(\"clean_title\")\n",
        "    k_iloc = df.columns.get_loc(\"clean_text\")\n",
        "    \n",
        "    for i in range(obs):\n",
        "        # no_emoji_text = emoji.replace_emoji(str(df.iloc[i, k]), replace='') #remove emoji\n",
        "        # no_emoji_html_text = cleanhtml(no_emoji_text)\n",
        "        clean_text = cleanhtml(str(df.iloc[i, k]))\n",
        "        # cleaned_text = re.sub(r'https://\\S+', '', no_emoji_html_text)  #remove links\n",
        "        df.iloc[i, k_iloc] = clean_text\n",
        "\n",
        "        clean_text = cleanhtml(str(df.iloc[i, j]))\n",
        "        # no_emoji_title = emoji.replace_emoji(str(df.iloc[i, j]), replace='') #remove emoji\n",
        "        # no_emoji_html_title = cleanhtml(no_emoji_title)  #remove html\n",
        "        # cleaned_title = re.sub(r'https://\\S+', '', no_emoji_html_title)  #remove links\n",
        "        clean_text = cleanhtml(str(df.iloc[i, j]))\n",
        "        df.iloc[i, j_iloc] = cleaned_title\n",
        "\n",
        "    df.to_csv(file + \".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean(rootdir):\n",
        "    \"\"\"\n",
        "    Clean all the tweets files from different dates\n",
        "    Args:\n",
        "        rootdir (string): the path of the tweets files\n",
        "    \"\"\"\n",
        "    os.chdir(rootdir)\n",
        "    subfiles = os.listdir(rootdir)\n",
        "\n",
        "    for sf in subfiles:\n",
        "        if sf == '.DS_Store':\n",
        "            continue\n",
        "        \n",
        "        # find all the tweets files under each day folder\n",
        "        for file in os.listdir(os.path.join(rootdir, sf)):\n",
        "            file_manager(os.path.join(subfilepath, file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# give the directory of the tweets files\n",
        "rootdir = '/Users/victor/Desktop/CS/UST_summer/test'\n",
        "\n",
        "clean(rootdir=rootdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Create the WordCloud</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "4mAFvUkPxjiy",
        "outputId": "c7f75636-4840-4947-ab79-4a36664b3bb2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3955b93ea8ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/jerrylin/Downloads/2022-02-26/UkraineConflict.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "fp = \"/Users/jerrylin/Downloads/2022-02-26/UkraineConflict.csv\"\n",
        "df = pd.read_csv(fp)\n",
        "df[\"title\"]\n",
        "j = df.columns.get_loc(\"title\")\n",
        "obs = len(df)\n",
        "textfile = open(\"titlelist.txt\", \"w+\")\n",
        "for i in range(obs):\n",
        "    textfile.write(str(f1.iloc[i, j])+ '\\n')\n",
        "textfile.close()\n",
        "text = open(\"titlelist.txt\", mode=\"r\", encoding=\"utf-8\").read()\n",
        "stopwords = STOPWORDS\n",
        "mask = np.array(Image.open(\"/Users/jerrylin/Downloads/ukraine.png\"))\n",
        "\n",
        "wc = WordCloud(\n",
        "    background_color = \"white\",\n",
        "    stopwords = stopwords,\n",
        "    mask=mask,\n",
        "    height = 8000,\n",
        "    width = 4000\n",
        ")\n",
        "\n",
        "wc.generate(text)\n",
        "wc.to_file('wordcloud_test.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hupMWgKhmldw"
      },
      "outputs": [],
      "source": [
        "ban_word = ['fuck', 'fucking', 'motherfucker', 'motherfucking', 'cunt', 'shit', 'bitch', 'asshole']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "WordCloud.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
